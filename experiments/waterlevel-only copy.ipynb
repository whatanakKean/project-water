{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T06:50:24.507697Z",
     "iopub.status.busy": "2024-09-09T06:50:24.507205Z",
     "iopub.status.idle": "2024-09-09T06:50:42.402429Z",
     "shell.execute_reply": "2024-09-09T06:50:42.401204Z",
     "shell.execute_reply.started": "2024-09-09T06:50:24.507658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 01:18:21.293240: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 01:18:21.297654: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-02 01:18:21.324833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730510301.480628   30529 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730510301.499890   30529 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-02 01:18:21.558158: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T06:50:42.404843Z",
     "iopub.status.busy": "2024-09-09T06:50:42.404193Z",
     "iopub.status.idle": "2024-09-09T06:50:46.102223Z",
     "shell.execute_reply": "2024-09-09T06:50:46.099247Z",
     "shell.execute_reply.started": "2024-09-09T06:50:42.404812Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ffw.mrcmekong.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>AVG</th>\n",
       "      <th>1992</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>floodLevel</th>\n",
       "      <th>alarmLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.479281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.140654</td>\n",
       "      <td>6.269608</td>\n",
       "      <td>5.489020</td>\n",
       "      <td>9.092484</td>\n",
       "      <td>5.459869</td>\n",
       "      <td>7.036275</td>\n",
       "      <td>7.262484</td>\n",
       "      <td>4.709412</td>\n",
       "      <td>4.009477</td>\n",
       "      <td>4.709281</td>\n",
       "      <td>6.199608</td>\n",
       "      <td>5.300261</td>\n",
       "      <td>5.333987</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.792758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.184002</td>\n",
       "      <td>2.262871</td>\n",
       "      <td>1.771895</td>\n",
       "      <td>1.952256</td>\n",
       "      <td>2.049587</td>\n",
       "      <td>1.856611</td>\n",
       "      <td>2.555734</td>\n",
       "      <td>2.435415</td>\n",
       "      <td>1.792308</td>\n",
       "      <td>1.689127</td>\n",
       "      <td>2.031904</td>\n",
       "      <td>2.354565</td>\n",
       "      <td>2.616292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.240000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.290000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.390000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>6.910000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>4.730000</td>\n",
       "      <td>6.790000</td>\n",
       "      <td>6.280000</td>\n",
       "      <td>6.370000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.770000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.340000</td>\n",
       "      <td>6.870000</td>\n",
       "      <td>10.490000</td>\n",
       "      <td>7.420000</td>\n",
       "      <td>8.440000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>6.380000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>7.430000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>7.920000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>8.130000</td>\n",
       "      <td>8.860000</td>\n",
       "      <td>9.950000</td>\n",
       "      <td>9.490000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.560000</td>\n",
       "      <td>9.220000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Max    Min         AVG        1992        1998        2000  \\\n",
       "count  153.000000  153.0  153.000000  153.000000  153.000000  153.000000   \n",
       "mean     9.479281    0.0    7.140654    6.269608    5.489020    9.092484   \n",
       "std      1.792758    0.0    2.184002    2.262871    1.771895    1.952256   \n",
       "min      4.900000    0.0    2.690000    2.040000    2.420000    4.700000   \n",
       "25%      8.240000    0.0    5.290000    4.400000    4.760000    7.620000   \n",
       "50%     10.390000    0.0    8.140000    6.910000    5.810000    9.760000   \n",
       "75%     10.770000    0.0    9.000000    8.340000    6.870000   10.490000   \n",
       "max     11.200000    0.0    9.450000    9.010000    7.920000   11.200000   \n",
       "\n",
       "             2016        2017        2018        2019        2020        2021  \\\n",
       "count  153.000000  153.000000  153.000000  153.000000  153.000000  153.000000   \n",
       "mean     5.459869    7.036275    7.262484    4.709412    4.009477    4.709281   \n",
       "std      2.049587    1.856611    2.555734    2.435415    1.792308    1.689127   \n",
       "min      1.940000    3.550000    2.590000    1.990000    1.640000    1.760000   \n",
       "25%      4.150000    4.670000    4.190000    2.420000    2.270000    3.220000   \n",
       "50%      5.640000    8.130000    8.140000    4.070000    4.170000    4.730000   \n",
       "75%      7.420000    8.440000    9.600000    6.630000    5.360000    6.380000   \n",
       "max      8.130000    8.860000    9.950000    9.490000    7.700000    7.560000   \n",
       "\n",
       "             2022        2023        2024  floodLevel  alarmLevel  \n",
       "count  153.000000  153.000000  153.000000       153.0       153.0  \n",
       "mean     6.199608    5.300261    5.333987        12.0        10.5  \n",
       "std      2.031904    2.354565    2.616292         0.0         0.0  \n",
       "min      3.240000    0.000000    0.000000        12.0        10.5  \n",
       "25%      3.840000    2.670000    2.750000        12.0        10.5  \n",
       "50%      6.790000    6.280000    6.370000        12.0        10.5  \n",
       "75%      7.840000    7.430000    7.160000        12.0        10.5  \n",
       "max      9.220000    8.260000    9.100000        12.0        10.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOWER_MEKONG_STATION_CODES =  [\n",
    "    \"STR\", # StungTreng\n",
    "    \"KRA\", # Kratie\n",
    "    \"KOM\", # Kompong Cham\n",
    "    \"PPB\", # Phnom Penh (Bassac)\n",
    "    \"PPP\", # Phnom Penh Port\n",
    "    \"KOH\", # Koh Khel (Bassac)\n",
    "    \"NEA\", # Neak Luong\n",
    "    \"PRE\", # Prek Kdam (Tonle Sap)\n",
    "    \"TCH\", # Tan Chau\n",
    "    \"CDO\", # Chau Doc (Bassac)\n",
    "]\n",
    "BASE_URL = \"http://ffw.mrcmekong.org/fetchwet_st.php?StCode=\"\n",
    "r = requests.get(BASE_URL+LOWER_MEKONG_STATION_CODES[3], verify=False)\n",
    "# soup = BeautifulSoup(r.content, 'html5lib')\n",
    "# body = soup.find('body')\n",
    "data_string = r.content.decode('utf-8')\n",
    "\n",
    "# Convert single quotes and remove any non-JSON parts\n",
    "data_string = data_string.replace('date_gmt:', '\"date_gmt\":')\n",
    "data_string = data_string.replace('Max:', '\"Max\":')\n",
    "data_string = data_string.replace('Min:', '\"Min\":')\n",
    "data_string = data_string.replace('AVG:', '\"AVG\":')\n",
    "data_string = data_string.replace('floodLevel:', '\"floodLevel\":')\n",
    "data_string = data_string.replace('alarmLevel:', '\"alarmLevel\":')\n",
    "for year in range(1992, 2025):\n",
    "    data_string = data_string.replace(f'{year}:', f'\"{year}\":')\n",
    "\n",
    "data_string = data_string.replace(',]', ']')\n",
    "\n",
    "# Now parse it into a list of dictionaries\n",
    "data = json.loads(data_string)\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df['date_gmt'] = df['date_gmt'].apply(lambda x: x.split(\"-\")[1]+\"-\"+x.split(\"-\")[2])\n",
    "df['station'] = LOWER_MEKONG_STATION_CODES[3]\n",
    "\n",
    "# Set date_gmt as index \n",
    "df.index = df['date_gmt']\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-09T06:50:46.103588Z",
     "iopub.status.idle": "2024-09-09T06:50:46.104174Z",
     "shell.execute_reply": "2024-09-09T06:50:46.103903Z",
     "shell.execute_reply.started": "2024-09-09T06:50:46.103881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>water_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE_GMT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10-23-2024</th>\n",
       "      <td>7.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-24-2024</th>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-27-2024</th>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-28-2024</th>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-31-2024</th>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            water_level\n",
       "DATE_GMT               \n",
       "10-23-2024         7.09\n",
       "10-24-2024         6.96\n",
       "10-27-2024         6.53\n",
       "10-28-2024         6.30\n",
       "10-31-2024         6.37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[['date_gmt', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']]\n",
    "df_filtered.set_index('date_gmt', inplace=True)\n",
    "df_filtered.reset_index(inplace=True)\n",
    "df_long = pd.melt(df_filtered, id_vars=['date_gmt'], value_vars=['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024'],\n",
    "                   var_name='Year', value_name='water_level')\n",
    "df_long['DATE_GMT'] = pd.to_datetime(df_long['date_gmt'] + '-' + df_long['Year'], format='%m-%d-%Y').dt.strftime('%m-%d-%Y')\n",
    "df_long = df_long[['DATE_GMT', 'water_level']]\n",
    "df_non_zero = df_long[df_long['water_level'] != 0]\n",
    "df_non_zero.set_index('DATE_GMT', inplace=True)\n",
    "df_non_zero.index.freq='D'\n",
    "# df_non_zero.plot(figsize=(12,6))\n",
    "df_non_zero.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import lxml\n",
    "\n",
    "# Define the path to your Excel file\n",
    "file_path = '../src/data/ManualData_Mainstream.xlsx'\n",
    "\n",
    "# Load the data initially without parsing dates\n",
    "data = pd.read_excel(\n",
    "    file_path,\n",
    "    sheet_name=\"in\",\n",
    "    skiprows=4,      \n",
    "    header=[0, 1, 2]\n",
    ")\n",
    "# Fill NaN rainfall with 0\n",
    "data.loc[:, (slice(None), slice(None), 'RF')] = data.loc[:, (slice(None), slice(None), 'RF')].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30529/371176613.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bassac_caktomuk['Date'] = bassac_caktomuk['Date'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
      "/tmp/ipykernel_30529/371176613.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bassac_caktomuk['Date'] = pd.to_datetime(bassac_caktomuk['Date'])\n",
      "/tmp/ipykernel_30529/371176613.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bassac_caktomuk['WL 7AM'] = bassac_caktomuk['WL 7AM'].interpolate(method='linear')\n",
      "/tmp/ipykernel_30529/371176613.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bassac_caktomuk['WL 7PM'] = bassac_caktomuk['WL 7PM'].interpolate(method='linear')\n"
     ]
    }
   ],
   "source": [
    "data.set_index('StaName', inplace=True)\n",
    "\n",
    "# Filter for \"Stung Treng\" measurements\n",
    "bassac_caktomuk = data.loc[:, pd.IndexSlice['Bassac Chaktomuk', 33401, :]]\n",
    "\n",
    "# Reset index to bring 'Date' back as a column\n",
    "bassac_caktomuk.reset_index(inplace=True)\n",
    "bassac_caktomuk.columns = bassac_caktomuk.columns.droplevel([0, 1])\n",
    "bassac_caktomuk.columns = ['Date', 'WL 7AM', 'WL 7PM', 'RF']\n",
    "bassac_caktomuk['Date'] = bassac_caktomuk['Date'].apply(lambda x: x[0] if isinstance(x, tuple) else x)\n",
    "bassac_caktomuk['Date'] = pd.to_datetime(bassac_caktomuk['Date'])\n",
    "bassac_caktomuk.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "bassac_caktomuk['WL 7AM'] = bassac_caktomuk['WL 7AM'].interpolate(method='linear')\n",
    "bassac_caktomuk['WL 7PM'] = bassac_caktomuk['WL 7PM'].interpolate(method='linear')\n",
    "\n",
    "\n",
    "# Drop Columns\n",
    "bassac_caktomuk = bassac_caktomuk.drop('WL 7PM', axis=1)\n",
    "bassac_caktomuk = bassac_caktomuk.drop('RF', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-09T06:50:46.105898Z",
     "iopub.status.idle": "2024-09-09T06:50:46.106455Z",
     "shell.execute_reply": "2024-09-09T06:50:46.106202Z",
     "shell.execute_reply.started": "2024-09-09T06:50:46.106179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.15  # proportion of the entire dataset for validation\n",
    "test_ratio = 0.15  # proportion of the entire dataset for testing\n",
    "\n",
    "# Calculate the split indices\n",
    "train_size = int(len(bassac_caktomuk) * train_ratio)\n",
    "valid_size = int(len(bassac_caktomuk) * valid_ratio)\n",
    "test_size = len(bassac_caktomuk) - train_size - valid_size\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "train = bassac_caktomuk.iloc[:train_size]\n",
    "valid = bassac_caktomuk.iloc[train_size:train_size + valid_size]\n",
    "test = bassac_caktomuk.iloc[train_size + valid_size:]\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train)  # Fit on train and transform all sets\n",
    "scaled_valid = scaler.transform(valid)\n",
    "scaled_test = scaler.transform(test)\n",
    "\n",
    "# Define look back and batch size\n",
    "look_back = 10  # Number of previous time steps to consider for prediction\n",
    "batch_size = 32  # Batch size\n",
    "\n",
    "# Create TimeseriesGenerator for training, validation, and testing data\n",
    "train_generator = TimeseriesGenerator(scaled_train, scaled_train, length=look_back, batch_size=batch_size)\n",
    "valid_generator = TimeseriesGenerator(scaled_valid, scaled_valid, length=look_back, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(scaled_test, scaled_test, length=look_back, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-09T06:50:46.107850Z",
     "iopub.status.idle": "2024-09-09T06:50:46.108409Z",
     "shell.execute_reply": "2024-09-09T06:50:46.108154Z",
     "shell.execute_reply.started": "2024-09-09T06:50:46.108132Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 01:18:33.662011: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/vscode/.local/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - loss: 0.0114 - val_loss: 0.0061\n",
      "Epoch 2/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 3/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 4/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 5/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 6/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 7/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 8/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 9/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 0.0011 - val_loss: 8.5125e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 9.6642e-04 - val_loss: 7.2080e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 5.8683e-04 - val_loss: 0.0019\n",
      "Epoch 13/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - loss: 0.0013 - val_loss: 4.9331e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - loss: 3.3375e-04 - val_loss: 6.0306e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 5.5414e-04 - val_loss: 0.0028\n",
      "Epoch 16/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.0024 - val_loss: 3.3520e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.6003e-04 - val_loss: 2.9951e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.8564e-04 - val_loss: 3.0385e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 2.2818e-04 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.0012 - val_loss: 2.4798e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 2.1713e-04 - val_loss: 2.0860e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - loss: 1.2340e-04 - val_loss: 1.9718e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - loss: 1.2921e-04 - val_loss: 2.8191e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 2.1384e-04 - val_loss: 1.6825e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.4004e-04 - val_loss: 9.7293e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 1.8071e-04 - val_loss: 1.6508e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 1.0089e-04 - val_loss: 1.5891e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 1.5468e-04 - val_loss: 1.6528e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 2.3848e-04 - val_loss: 2.4387e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 1.1229e-04 - val_loss: 1.4797e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - loss: 1.6901e-04 - val_loss: 1.4393e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - loss: 7.8770e-05 - val_loss: 1.7767e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 3.0604e-04 - val_loss: 1.9863e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 1.7887e-04 - val_loss: 1.3565e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - loss: 1.1557e-04 - val_loss: 1.2900e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 7.9585e-05 - val_loss: 1.1066e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 7.4899e-05 - val_loss: 2.1007e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - loss: 1.4332e-04 - val_loss: 0.0023\n",
      "Epoch 39/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 9.6685e-04 - val_loss: 1.2751e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - loss: 1.5840e-04 - val_loss: 1.0800e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 9.2382e-05 - val_loss: 1.0969e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - loss: 1.8477e-04 - val_loss: 1.1614e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 1.7497e-04 - val_loss: 1.2256e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.5293e-05 - val_loss: 1.4793e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 2.0838e-04 - val_loss: 1.1712e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.9598e-05 - val_loss: 2.2749e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.0309e-04 - val_loss: 2.4024e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 2.9532e-04 - val_loss: 3.2511e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - loss: 3.2126e-04 - val_loss: 2.1885e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - loss: 1.9447e-04 - val_loss: 1.1507e-04\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(look_back, scaled_train.shape[1])))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(GRU(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Set up early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(train_generator, \n",
    "                    validation_data=valid_generator, \n",
    "                    epochs=100, \n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-09T06:50:46.111965Z",
     "iopub.status.idle": "2024-09-09T06:50:46.112505Z",
     "shell.execute_reply": "2024-09-09T06:50:46.112264Z",
     "shell.execute_reply.started": "2024-09-09T06:50:46.112242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdates\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmdates\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model on test data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Inverse scale predictions to original values\n",
    "predictions_inverse = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Prepare the test data corresponding to predictions for comparison\n",
    "test_data = scaled_test[look_back:]  # Offset by 'look_back' to align with generator output\n",
    "original_test_data_inverse = scaler.inverse_transform(test_data)\n",
    "\n",
    "# Adjust test_dates to match the length of predictions\n",
    "# Assuming 'df_non_zero' contains the full dataset with a DateTime index\n",
    "test_dates = bassac_caktomuk.index[len(train) + len(valid) + look_back: len(train) + len(valid) + len(predictions) + look_back]\n",
    "\n",
    "# Plot predicted vs original values with dates\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_dates, original_test_data_inverse[:, 0], label='Original Values', color='blue')\n",
    "plt.plot(test_dates, predictions_inverse[:, 0], label='Predicted Values', linestyle='dashed', color='orange')\n",
    "plt.title('Predicted vs Original Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Water Level')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
